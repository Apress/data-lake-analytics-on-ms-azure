{"cells":[{"cell_type":"markdown","source":["Install the Azure ML SDK on your Azure Databricks Cluster"],"metadata":{}},{"cell_type":"code","source":["import azureml.core\nazureml.core.VERSION"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: &#39;1.8.0&#39;</div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["Initialize Azure ML Workspace"],"metadata":{}},{"cell_type":"code","source":["#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"fc489c93-72d7-4073-8b24-e2f4ea9336f0\"\n\n#Provide a name for the new Resource Group that will contain Azure ML related services \nresource_group = \"book\"\n\n# Provide a unique name (like \"aml-bigdata-lab-SUFFIX\") and region for the Azure Machine Learning Workspace that will be created\nworkspace_name = \"sampleMLWorkspace\"\nworkspace_region = \"southeastasia\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["Create an Azure ML Workspace"],"metadata":{}},{"cell_type":"code","source":["import azureml.core\n\n# import the Workspace class and check the azureml SDK version\nfrom azureml.core import Workspace\n\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True\n)\n\nprint(\"Provisioning complete.\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Performing interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code GNHPGPQUN to authenticate.\nInteractive authentication successfully completed.\nProvisioning complete.\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Persist the Workspace configuration"],"metadata":{}},{"cell_type":"code","source":["import os\nimport shutil\n\nws = Workspace(\n    workspace_name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group)\n\n# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\nws.write_config()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Take a look at the contents of the generated configuration file by running the following cell:"],"metadata":{}},{"cell_type":"code","source":["%sh\ncat /databricks/driver/.azureml/config.json"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#34;Id&#34;: null, &#34;Scope&#34;: &#34;/subscriptions/fc489c93-72d7-4073-8b24-e2f4ea9336f0/resourceGroups/book/providers/Microsoft.MachineLearningServices/workspaces/sampleMLWorkspace&#34;}</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Copy the config file to DBFS"],"metadata":{}},{"cell_type":"code","source":["#persist the config file to dbfs so that it can be used for the other notebooks.\naml_config_local = 'file:' + os.getcwd() + '/.azureml/'\naml_config_dbfs = '/dbfs/' + 'aml_config'\n\nif os.path.isfile(aml_config_dbfs) or os.path.isdir(aml_config_dbfs):\n    shutil.rmtree(aml_config_dbfs)\n\ndbutils.fs.cp(aml_config_local, aml_config_dbfs, recurse=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: True</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Deploy model to Azure Container Instance (ACI)"],"metadata":{}},{"cell_type":"code","source":["import os\n\nfrom pyspark.ml import PipelineModel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Copy the model from DBFS"],"metadata":{}},{"cell_type":"code","source":["##NOTE: service deployment always gets the model from the current working dir. \nmodel_name = \"flightDelayModel\"\nmodel_path_dbfs = \"/flightDelayModel/\"#os.path.join(\"/dbfs/models\", model_name)\nmodel_path_local = \"file:\" + os.getcwd() + \"/\" + model_name + \"/\"\n\nprint(\"copy model from dbfs {} to local {}\".format(model_path_dbfs, model_path_local))\ndbutils.fs.cp(model_path_dbfs, model_path_local, recurse=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">copy model from dbfs /flightDelayModel/ to local file:/databricks/driver/flightDelayModel/\nOut[10]: True</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Register the model with Azure Machine Learning"],"metadata":{}},{"cell_type":"code","source":["import azureml.core\nfrom azureml.core.workspace import Workspace\n\n#get the config file from dbfs\ndbutils.fs.cp(aml_config_dbfs, aml_config_local, recurse=True)\n\nws = Workspace.from_config()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["#Register the model\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_name, # this points to a local file or folder in the current working dir\n                       model_name = model_name, # this is the name the model is registered with                 \n                       description = \"Flight Delay Prediction Model\",\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model flightDelayModel\nflightDelayModel Flight Delay Prediction Model 1\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["Create the scoring web service"],"metadata":{}},{"cell_type":"code","source":["#%%writefile score_sparkml.py\nscore_sparkml = \"\"\"\n\nimport json\n\ndef init():\n    try:\n        # One-time initialization of PySpark and predictive model\n        import pyspark\n        from pyspark.ml import PipelineModel\n        from azureml.core.model import Model\n        \n        global trainedModel\n        global spark\n        \n        spark = pyspark.sql.SparkSession.builder.appName(\"Scoring\").getOrCreate()\n      \n        model_name = \"flightDelayModel\" \n        \n        model_path = Model.get_model_path(model_name)\n\n        trainedModel = PipelineModel.load(model_path)\n\n    except Exception as e:\n        print(\"Exception in init: \" + str(e))\n        trainedModel = e\n\ndef run(input_df):\n    response = ''    \n\n    if isinstance(trainedModel, Exception):\n        return json.dumps({\"Exception\":trainedModel})\n\n    try:\n        print(\"received: \" + input_df)\n        \n        sc = spark.sparkContext\n      \n        # Set inferSchema=true to prevent the float values from being seen as strings\n        # which can later cause the VectorAssembler to throw an error: 'Data type StringType is not supported.'\n        df = spark.read.option(\"inferSchema\", \"true\").json(sc.parallelize([input_df]))\n      \n        #Get prediction results for the dataframe\n        score = trainedModel.transform(df)\n        predictions = score.collect()\n        \n        #Get each scored result (prediction and confidence)\n        preds = [{\"prediction\":str(result['prediction']), \"confidence\":str(result['probability'])} for result in predictions]\n        \n        response = json.dumps(preds)\n        \n        print(\"response: \" + str(response))\n        \n    except Exception as e:\n        print(\"Exception in run: \" + str(e))\n        return (str(e))\n\n    # Return results\n    return response\n    \n\"\"\"\n\nexec(score_sparkml)\n\nwith open(\"score_sparkml.py\", \"w\") as file:\n    file.write(score_sparkml)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["Test the scoring script locally and confirm that it works as desired."],"metadata":{}},{"cell_type":"code","source":["import json\n\n# Create two records for testing the prediction\ntest_input1 = {\"OriginAirportCode\":\"SAT\",\"Month\":5,\"DayofMonth\":5,\"CRSDepHour\":13,\"DayOfWeek\":7,\"Carrier\":\"MQ\",\"DestAirportCode\":\"ORD\",\"WindSpeed\":9,\"SeaLevelPressure\":30.03,\"HourlyPrecip\":0}\n\ntest_input2 = {\"OriginAirportCode\":\"ATL\",\"Month\":2,\"DayofMonth\":5,\"CRSDepHour\":8,\"DayOfWeek\":4,\"Carrier\":\"MQ\",\"DestAirportCode\":\"MCO\",\"WindSpeed\":3,\"SeaLevelPressure\":31.03,\"HourlyPrecip\":0}\n\n# test init() in local notebook# test  \ninit()\n\n# package the inputs into a JSON string and test run() in local notebook\ntest_inputs = [test_input1, test_input2] \njson_str_test_inputs = json.dumps(test_inputs)\nrun(json_str_test_inputs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">received: [{&#34;OriginAirportCode&#34;: &#34;SAT&#34;, &#34;Month&#34;: 5, &#34;DayofMonth&#34;: 5, &#34;CRSDepHour&#34;: 13, &#34;DayOfWeek&#34;: 7, &#34;Carrier&#34;: &#34;MQ&#34;, &#34;DestAirportCode&#34;: &#34;ORD&#34;, &#34;WindSpeed&#34;: 9, &#34;SeaLevelPressure&#34;: 30.03, &#34;HourlyPrecip&#34;: 0}, {&#34;OriginAirportCode&#34;: &#34;ATL&#34;, &#34;Month&#34;: 2, &#34;DayofMonth&#34;: 5, &#34;CRSDepHour&#34;: 8, &#34;DayOfWeek&#34;: 4, &#34;Carrier&#34;: &#34;MQ&#34;, &#34;DestAirportCode&#34;: &#34;MCO&#34;, &#34;WindSpeed&#34;: 3, &#34;SeaLevelPressure&#34;: 31.03, &#34;HourlyPrecip&#34;: 0}]\nresponse: [{&#34;prediction&#34;: &#34;1.0&#34;, &#34;confidence&#34;: &#34;[0.43960711204899156,0.5603928879510084]&#34;}, {&#34;prediction&#34;: &#34;0.0&#34;, &#34;confidence&#34;: &#34;[0.6991391413245519,0.3008608586754481]&#34;}]\nOut[14]: &#39;[{&#34;prediction&#34;: &#34;1.0&#34;, &#34;confidence&#34;: &#34;[0.43960711204899156,0.5603928879510084]&#34;}, {&#34;prediction&#34;: &#34;0.0&#34;, &#34;confidence&#34;: &#34;[0.6991391413245519,0.3008608586754481]&#34;}]&#39;</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["Deployment"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name':'Flight Delay Prediction'}, \n    description = 'Predicts if a flight will be delayed by 15 minutes or more.')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["Next, we will build an environment that will host our service"],"metadata":{}},{"cell_type":"code","source":["from azureml.core import Environment\n\nenvironment = Environment.get(ws, name=\"AzureML-PySpark-MmlSpark-0.15\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["driver_file = \"score_sparkml.py\"\n\nfrom azureml.core.model import InferenceConfig\n\ninference_config = InferenceConfig(entry_script=driver_file, environment=environment)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["service_name = \"sparkmlservicedb001\"\n\nfrom azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.exceptions import WebserviceException\n\ntry:\n    # if you want to get existing service below is the command\n    # since aci name needs to be unique in subscription deleting existing aci if any\n    # we use aci_service_name to create azure aci\n    service = Webservice(ws, name=service_name)\n    if service:\n        service.delete()\nexcept WebserviceException as e:\n    print()\n\nservice = Model.deploy(ws, service_name, [mymodel], inference_config, aci_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nRunning............................................................\nSucceeded\nACI service creation operation finished, operation &#34;Succeeded&#34;\nHealthy\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["Test the deployed service"],"metadata":{}},{"cell_type":"code","source":["service.run(input_data = json_str_test_inputs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: &#39;[{&#34;prediction&#34;: &#34;1.0&#34;, &#34;confidence&#34;: &#34;[0.43960711204899156,0.5603928879510084]&#34;}, {&#34;prediction&#34;: &#34;0.0&#34;, &#34;confidence&#34;: &#34;[0.6991391413245519,0.3008608586754481]&#34;}]&#39;</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["Retrieve the web service URL"],"metadata":{}},{"cell_type":"code","source":["print(service.scoring_uri)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">http://975639e4-2f53-40b2-8d5a-f906da87d107.southeastasia.azurecontainer.io/score\n</div>"]}}],"execution_count":33}],"metadata":{"name":"03 Deploy as Web Service","notebookId":3293225955199312},"nbformat":4,"nbformat_minor":0}
